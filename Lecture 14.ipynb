{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 14. object detection (advanced)\n",
    "\n",
    "물체의 종류와 위치 파악, 테두리 그리기, bounding box...  \n",
    "그리드 형식의 데이터 처리 : CNN (Convolutional Neural Network / 합성곱 신경망)  \n",
    "\n",
    "Training : label 준비 -> 인공지능에게 학습  \n",
    "Inference (Prediction) : 추론  \n",
    "Training -> inference  \n",
    "\n",
    "**YOLO : You Only Look Once (CNN 기반, object detection)**  \n",
    "resizing -> CNN 통과 -> detection complete (drawing bounding box)  \n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이미 training된 지능을 사용 (pre-trained model weights)**\n",
    "\n",
    "• Pre-trained model weights:\n",
    "https://pjreddie.com/media/files/yolov3.weights   \n",
    "\n",
    "• Model configuration file (text file): https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg   \n",
    "\n",
    "• COCO class names (text file): https://github.com/pjreddie/darknet/blob/master/data/coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w, c :  1020 1280 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOLO step 0 : shape -> height, weight, channel 값 가짐\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"poker.jpg\")\n",
    "h, w, c = img.shape\n",
    "print (\"h, w, c : \", h, w, c)\n",
    "\n",
    "cv2.imshow ('poker', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "# mac에서 opencv 팝업창 안닫힐때 뒤에 항상 붙여주기\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w, c :  1020 1280 3\n",
      "blob shape: (1, 3, 416, 416)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOLO step 1 : DNN이 인식할 수 있는 값 = blob \n",
    "# 이미지를 blob으로 변환\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"poker.jpg\")\n",
    "h, w, c = img.shape\n",
    "print (\"h, w, c : \", h, w, c)\n",
    "\n",
    "# get blob from original img \n",
    "# 원본, 소수값으로 변환 (비율로 변환 / min-max normalization : 0~1), 고정된 크기로 변환 (정사각형), (0, 0, 0), BGR을 RGB로 할 것인가?, 고정된 크기로 변환 시에 자르기 가능?\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "print ('blob shape:', blob.shape) \n",
    "# blob shape : (batch, channel, 가로크기, 세로크기)\n",
    "\n",
    "cv2.imshow (\"blob\", blob[0, 0, :, :])\n",
    "cv2.waitKey()\n",
    "\n",
    "# mac에서 opencv 팝업창 안닫힐때 뒤에 항상 붙여주기\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w, c :  1020 1280 3\n",
      "blob shape: (1, 3, 416, 416)\n",
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# mac에서 opencv 팝업창 안닫힐때 뒤에 항상 붙여주기\\ncv2.destroyAllWindows()\\ncv2.waitKey(1)\\ncv2.waitKey(1)\\ncv2.waitKey(1)\\ncv2.waitKey(1)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOLO step 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"poker.jpg\")\n",
    "h, w, c = img.shape\n",
    "print (\"h, w, c : \", h, w, c)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "print ('blob shape:', blob.shape) \n",
    "\n",
    "# 파일 읽기\n",
    "with open(\"coco.names\", \"r\") as f : \n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "print (classes)\n",
    "\n",
    "'''# mac에서 opencv 팝업창 안닫힐때 뒤에 항상 붙여주기\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w, c :  1020 1280 3\n",
      "blob shape: (1, 3, 416, 416)\n",
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "# YOLO step 3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"poker.jpg\")\n",
    "h, w, c = img.shape\n",
    "print (\"h, w, c : \", h, w, c)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "print ('blob shape:', blob.shape) \n",
    "\n",
    "# 파일 읽기\n",
    "with open(\"coco.names\", \"r\") as f : \n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# load pre-trained YOLO model (net : network)\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# set output layers (layer 중에서 output을 내기 위한 layer 지정)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "print (output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w, c :  1020 1280 3\n",
      "blob shape: (1, 3, 416, 416)\n",
      "['yolo_82', 'yolo_94', 'yolo_106']\n",
      "shape of the first output (507, 85)\n",
      "[2.8508145e-02 4.3023549e-02 2.6924250e-01 1.6787274e-01 1.3246119e-09]\n"
     ]
    }
   ],
   "source": [
    "# YOLO step 4 \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"poker.jpg\")\n",
    "h, w, c = img.shape\n",
    "print (\"h, w, c : \", h, w, c)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "print ('blob shape:', blob.shape) \n",
    "\n",
    "# 파일 읽기\n",
    "with open(\"coco.names\", \"r\") as f : \n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# load pre-trained YOLO model (net : network)\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# set output layers (layer 중에서 output을 내기 위한 layer 지정)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "print (output_layers)\n",
    "\n",
    "# detect objects\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "print (\"shape of the first output\", outs[0].shape)\n",
    "print (outs[0][0, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape: 427 640 3\n",
      "blob shape: (1, 3, 416, 416)\n",
      "number of classes = 80\n",
      "output layers: ['yolo_82', 'yolo_94', 'yolo_106']\n",
      "number of dectected objects = 30\n",
      "number of final objects = 7\n",
      "class person detected at 184, 21, 148, 295\n",
      "class person detected at 322, 37, 156, 294\n",
      "class person detected at 23, 114, 184, 278\n",
      "class person detected at 412, 85, 208, 307\n",
      "class laptop detected at 308, 257, 146, 107\n",
      "class person detected at 68, 127, 114, 164\n",
      "class tie detected at 111, 212, 20, 73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "img = cv2.imread('people.jpg')\n",
    "height, width, channel = img.shape\n",
    "print('original image shape:', height, width, channel)\n",
    "\n",
    "# get blob from image\n",
    "blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "print('blob shape:', blob.shape)\n",
    "\n",
    "# read coco object names\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print('number of classes =', len(classes))\n",
    "\n",
    "# load pre-trained yolo model from configuration and weight files\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# set output layers\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "print('output layers:', output_layers)\n",
    "\n",
    "# detect objects\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# get bounding boxes and confidence socres\n",
    "class_ids = []\n",
    "confidence_scores = []\n",
    "boxes = []\n",
    "\n",
    "for out in outs: # for each detected object\n",
    "\n",
    "    for detection in out: # for each bounding box\n",
    "\n",
    "        scores = detection[5:] # scores (confidence) for all classes\n",
    "        class_id = np.argmax(scores) # class id with the maximum score (confidence)\n",
    "        confidence = scores[class_id] # the maximum score\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            # bounding box coordinates\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidence_scores.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "print('number of dectected objects =', len(boxes))\n",
    "\n",
    "# non maximum suppression\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, 0.5, 0.4)\n",
    "print('number of final objects =', len(indices))\n",
    "\n",
    "# draw bounding boxes with labels on image\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "for i in range(len(boxes)):\n",
    "    if i in indices:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        print(f'class {label} detected at {x}, {y}, {w}, {h}')\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label, (x, y - 10), font, 1, color, 2)\n",
    "\n",
    "cv2.imshow('Objects', img)\n",
    "cv2.waitKey()\n",
    "# mac에서 opencv 팝업창 안닫힐때 뒤에 항상 붙여주기\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
